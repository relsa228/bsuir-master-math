{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bbbac958-3921-48ab-8f69-b828f648350c",
   "metadata": {},
   "source": [
    "# Лабораторная работа №3. Реализация сверточной нейронной сети"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cbd6709d-528c-463e-a57f-e76ecacf4b97",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-01 01:33:10.308485: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-05-01 01:33:10.309156: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-05-01 01:33:10.312233: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-05-01 01:33:10.321311: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1746052390.336659    4008 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1746052390.341433    4008 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1746052390.354017    4008 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1746052390.354060    4008 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1746052390.354062    4008 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1746052390.354064    4008 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-05-01 01:33:10.358686: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "train_dir = \"notMNIST_small/train\"\n",
    "test_dir = \"notMNIST_small/test\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31326cba-d043-4e4b-b0ec-c2c4177323b9",
   "metadata": {},
   "source": [
    "Функция загрузки данных из папок"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a333f81e-f996-4575-89ba-4b53e6ed1a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(folder):\n",
    "    images = []\n",
    "    labels = []\n",
    "    label_map = {chr(i): idx for idx, i in enumerate(range(ord('A'), ord('J')+1))}\n",
    "\n",
    "    for label in os.listdir(folder):\n",
    "        label_path = os.path.join(folder, label)\n",
    "        if os.path.isdir(label_path):\n",
    "            for file in os.listdir(label_path):\n",
    "                img_path = os.path.join(label_path, file)\n",
    "                img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "                img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "                if img is None:\n",
    "                    print(f\"Ошибка загрузки изображения: {img_path}\")\n",
    "                    continue  # Пропускаем этот файл\n",
    "                img = cv2.resize(img, (28, 28))\n",
    "                images.append(img)\n",
    "                labels.append(label_map[label])\n",
    "\n",
    "    return np.array(images), np.array(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6cd85c3-edc4-4017-aee0-df2ab4d61e91",
   "metadata": {},
   "source": [
    "Загрузка и нормализация данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0fb0929-86a3-4605-ad53-48017be63b1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ошибка загрузки изображения: notMNIST_small/train/A/RGVtb2NyYXRpY2FCb2xkT2xkc3R5bGUgQm9sZC50dGY=.png\n",
      "Ошибка загрузки изображения: notMNIST_small/train/F/Q3Jvc3NvdmVyIEJvbGRPYmxpcXVlLnR0Zg==.png\n"
     ]
    }
   ],
   "source": [
    "train_images, train_labels = load_data(train_dir)\n",
    "test_images, test_labels = load_data(test_dir)\n",
    "\n",
    "train_images = train_images / 255.0\n",
    "test_images = test_images / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9eccfb1-0fc8-4c43-8a2e-c74938dcfd3d",
   "metadata": {},
   "source": [
    "Преобразование формы данных и определние модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "62241468-80a5-48a1-8174-4d768e992fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_images.reshape(-1, 28, 28, 1)\n",
    "test_images = test_images.reshape(-1, 28, 28, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d03f4058-28c1-4b0e-8577-0529f8981b8d",
   "metadata": {},
   "source": [
    "**Задание 1.** Реализуйте нейронную сеть с двумя сверточными слоями, и одним полносвязным с нейронами с кусочно-линейной функцией активации. Какова точность построенное модели?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e912d99a-1cda-4182-b9fe-c718555c0449",
   "metadata": {},
   "source": [
    "Предлагается создать модель, реализующую несколько слоев: \n",
    "- `Сверточные слои` - хороши при проведении локального анализа различий\n",
    "- `Полносвязный слой` - необходим для контроля глобального контекста и принятия решений"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b8f627-909d-4ac7-b6ca-60590194c52a",
   "metadata": {},
   "source": [
    "Проектирование модели и инициализация обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "851a9791-2952-4199-b040-890b60c2eed8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/relsa/.var/app/org.jupyter.JupyterLab/config/jupyterlab-desktop/envs/env_1/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "2025-05-01 01:33:14.803406: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 23ms/step - accuracy: 0.8185 - loss: 0.6293 - val_accuracy: 0.9227 - val_loss: 0.2559\n",
      "Epoch 2/10\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 23ms/step - accuracy: 0.9493 - loss: 0.1676 - val_accuracy: 0.9289 - val_loss: 0.2289\n",
      "Epoch 3/10\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 23ms/step - accuracy: 0.9715 - loss: 0.0942 - val_accuracy: 0.9313 - val_loss: 0.2620\n",
      "Epoch 4/10\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9836 - loss: 0.0548 - val_accuracy: 0.9281 - val_loss: 0.3036\n",
      "Epoch 5/10\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 23ms/step - accuracy: 0.9893 - loss: 0.0346 - val_accuracy: 0.9313 - val_loss: 0.3260\n",
      "Epoch 6/10\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 23ms/step - accuracy: 0.9908 - loss: 0.0351 - val_accuracy: 0.9321 - val_loss: 0.3775\n",
      "Epoch 7/10\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 23ms/step - accuracy: 0.9932 - loss: 0.0261 - val_accuracy: 0.9281 - val_loss: 0.3904\n",
      "Epoch 8/10\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 23ms/step - accuracy: 0.9952 - loss: 0.0188 - val_accuracy: 0.9353 - val_loss: 0.3766\n",
      "Epoch 9/10\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 23ms/step - accuracy: 0.9951 - loss: 0.0153 - val_accuracy: 0.9310 - val_loss: 0.4051\n",
      "Epoch 10/10\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 23ms/step - accuracy: 0.9962 - loss: 0.0178 - val_accuracy: 0.9294 - val_loss: 0.4257\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7a4cee8238f0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)), # Сверточный\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'), # Сверточный\n",
    "    layers.Flatten(), # Преобразование многомерного тензора в одномерный массив\n",
    "    layers.Dense(128, activation='relu'), # Полносвязный\n",
    "    layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_images, train_labels, epochs=10, validation_data=(test_images, test_labels))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c502f68b-4670-4704-9b6d-700a83f9ac80",
   "metadata": {},
   "source": [
    "Оценка точности"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "58808494-3b80-4484-81ee-661f6db06ec2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117/117 - 1s - 12ms/step - accuracy: 0.9294 - loss: 0.4257\n",
      "Точность модели: 92.94%\n",
      "Потери: 0.42569679021835327\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(test_images, test_labels, verbose=2)\n",
    "print(f'Точность модели: {test_acc * 100:.2f}%\\nПотери: {test_loss}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ac41f4a-0e78-40cf-a0b9-232bf12aaa16",
   "metadata": {},
   "source": [
    "Обучение шло довольно медленно. Точность модели на обучающем массиве данных была крайне высокая (`99%`) при этом на тестовом наборе она резко упала до `93%`, что свидетельствует о переобучении."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b8cbfd-164b-4885-90d1-3ba4639ee856",
   "metadata": {},
   "source": [
    "**Задание 2.** Замените сверточные слои на слои, реализующие операцию пулинга (Pooling) с функцией максимума или среднего. Как это повлияло на точность классификатора?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06dc437f-29be-485a-9cc6-7422d659227e",
   "metadata": {},
   "source": [
    "`Пуллинг` позволит значительно сократить вычислительную сложность обучения модели и снизить риск переобучения."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7142873b-22b1-4c63-86de-4a7cc223ea75",
   "metadata": {},
   "source": [
    "Проектирование модели и инициализация обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "157e1f5e-0dff-430b-8697-d36298c43c62",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/relsa/.var/app/org.jupyter.JupyterLab/config/jupyterlab-desktop/envs/env_1/lib/python3.12/site-packages/keras/src/layers/pooling/base_pooling.py:23: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(name=name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6504 - loss: 1.2829 - val_accuracy: 0.8851 - val_loss: 0.4633\n",
      "Epoch 2/10\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8734 - loss: 0.4765 - val_accuracy: 0.8897 - val_loss: 0.4186\n",
      "Epoch 3/10\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8893 - loss: 0.4147 - val_accuracy: 0.8977 - val_loss: 0.3824\n",
      "Epoch 4/10\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8916 - loss: 0.3938 - val_accuracy: 0.8988 - val_loss: 0.3766\n",
      "Epoch 5/10\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8958 - loss: 0.3792 - val_accuracy: 0.9053 - val_loss: 0.3492\n",
      "Epoch 6/10\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9004 - loss: 0.3550 - val_accuracy: 0.9071 - val_loss: 0.3356\n",
      "Epoch 7/10\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9048 - loss: 0.3346 - val_accuracy: 0.9074 - val_loss: 0.3364\n",
      "Epoch 8/10\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9121 - loss: 0.3176 - val_accuracy: 0.9058 - val_loss: 0.3233\n",
      "Epoch 9/10\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9082 - loss: 0.3170 - val_accuracy: 0.9133 - val_loss: 0.3204\n",
      "Epoch 10/10\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9150 - loss: 0.3040 - val_accuracy: 0.9138 - val_loss: 0.3089\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7a4ced95fe00>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    layers.MaxPooling2D((2, 2), input_shape=(28, 28, 1)),\n",
    "    layers.AveragePooling2D((2, 2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_images, train_labels, epochs=10, validation_data=(test_images, test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be2e66e-1c5f-4bde-9c66-3612abcaa844",
   "metadata": {},
   "source": [
    "Оценка точности"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "738edb36-2052-4793-aedd-e6ae27ca1786",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117/117 - 0s - 2ms/step - accuracy: 0.9138 - loss: 0.3089\n",
      "Точность модели: 91.38%\n",
      "Потери: 0.3089263439178467\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(test_images, test_labels, verbose=2)\n",
    "print(f'Точность модели: {test_acc * 100:.2f}%\\nПотери: {test_loss}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d5b2402-3225-4a74-94e2-58f665912776",
   "metadata": {},
   "source": [
    "Видно, что обучение прошло крайне быстро. При этом результаты на обучающей выборке примерно равны результатам на тестовой. Однако сам по себе результат в `91%` является регрессом по сравнению с моделью, построенной на сверточных слоях. \n",
    "\n",
    "Это объяснятся тем, что при `пуллинге` уменьшается размер признакового пространства, сокращая количество параметров и вычислительных затрат, однако падает и чувствительность модели к мелким, но важным деталям, что сильно влияет на точность."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7b65a06-6c80-4455-8e0d-a1cc759156c4",
   "metadata": {},
   "source": [
    "**Задание 3.** Реализуйте классическую архитектуру сверточных сетей [LeNet-5](http://yann.lecun.com/exdb/lenet/). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b293cc8e-5928-4f50-8076-8a5fb764a38f",
   "metadata": {},
   "source": [
    "Архитектура `LeNet-5` является отличным компромиссом, который соединяет в себе точность `сверточных` слоев и оптимизацию, которую дает использование `пуллинга`. \n",
    "\n",
    "Общая схема архитектуры выглядит следующим образом: \n",
    "\n",
    "![alt](https://upload.wikimedia.org/wikipedia/commons/5/5e/LeNet-5_architecture_block_diagram.svg)\n",
    "\n",
    "Как видно, имеется две пары слоев {`сверточный`, `пуллинг`} и три полносвязных слоя, один из которых является выходным.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d6479c-d74b-43ec-8f7e-111dbef1fbdc",
   "metadata": {},
   "source": [
    "Проектирование модели и инициализация обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "31d9a414-1b72-451a-88b8-174178044f37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7536 - loss: 0.8231 - val_accuracy: 0.8975 - val_loss: 0.3543\n",
      "Epoch 2/10\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9068 - loss: 0.3148 - val_accuracy: 0.9192 - val_loss: 0.2767\n",
      "Epoch 3/10\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9238 - loss: 0.2506 - val_accuracy: 0.9294 - val_loss: 0.2496\n",
      "Epoch 4/10\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9403 - loss: 0.1899 - val_accuracy: 0.9257 - val_loss: 0.2501\n",
      "Epoch 5/10\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9537 - loss: 0.1525 - val_accuracy: 0.9308 - val_loss: 0.2329\n",
      "Epoch 6/10\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9602 - loss: 0.1257 - val_accuracy: 0.9353 - val_loss: 0.2271\n",
      "Epoch 7/10\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9658 - loss: 0.1077 - val_accuracy: 0.9361 - val_loss: 0.2216\n",
      "Epoch 8/10\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9760 - loss: 0.0812 - val_accuracy: 0.9345 - val_loss: 0.2334\n",
      "Epoch 9/10\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9815 - loss: 0.0631 - val_accuracy: 0.9361 - val_loss: 0.2341\n",
      "Epoch 10/10\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9860 - loss: 0.0524 - val_accuracy: 0.9348 - val_loss: 0.2478\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7a4cb468df40>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    layers.Conv2D(6, (5, 5), activation='tanh', padding='same', input_shape=(28, 28, 1)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "\n",
    "    layers.Conv2D(16, (5, 5), activation='tanh'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(120, activation='tanh'),\n",
    "    layers.Dense(84, activation='tanh'),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_images, train_labels, epochs=10, validation_data=(test_images, test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebc4c170-887f-4007-bd91-f57b0f47dde9",
   "metadata": {},
   "source": [
    "Оценка точности"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9cd63604-694c-4bd6-b480-f4e78ed95772",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117/117 - 0s - 2ms/step - accuracy: 0.9348 - loss: 0.2478\n",
      "Точность модели LeNet-5: 93.48%\n",
      "Потери: 0.24784143269062042\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(test_images, test_labels, verbose=2)\n",
    "print(f'Точность модели LeNet-5: {test_acc * 100:.2f}%\\nПотери: {test_loss}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1df6549-417d-4e1f-acba-be21bccc5633",
   "metadata": {},
   "source": [
    "Использование `пуллинга` совместно со `сверточными` слоями действительно помогло снизить влияние переобучения и оптимизировало сам обучающий процесс. \n",
    "\n",
    "В итоге точность модели в итоге повысилась до `94%`, при этом время обучения сократилось на `56 секунд`, а разница между точностью на обучающей и тестовой выборках уменьшилась на `1,86%`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
